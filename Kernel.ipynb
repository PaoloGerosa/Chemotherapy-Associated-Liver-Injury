{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kernel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloGerosa/Chemotherapy-Associated-Liver-Injury/blob/main/Kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLEzgHRQ7HTU"
      },
      "source": [
        "# Upload Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uLSFcO-7ObQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import scipy.stats\n",
        "from scipy import ndimage\n",
        "from skimage import data\n",
        "from skimage.measure import shannon_entropy\n",
        "from skimage.filters.rank import entropy as f_entropy\n",
        "from skimage.morphology import disk, ball\n",
        "from statistics import mean\n",
        "from statistics import variance \n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1SmpFxOCVK8"
      },
      "source": [
        "# Calcolo Kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3_bx5O6Q8BE1",
        "outputId": "79a76a57-7867-4560-a0af-79f09c919968"
      },
      "source": [
        "def abs_diff_metric(pixels):\n",
        "    sum = 0\n",
        "    center = len(pixels)//2\n",
        "    for i in range(len(pixels)):\n",
        "      sum += np.abs(pixels[i]-pixels[center])\n",
        "    return sum\n",
        "\n",
        "def make_filters(df, kernel_dim):\n",
        "  \n",
        "  stat_features = {}\n",
        "  stat_quantities = {}\n",
        "  histograms = {}\n",
        "  second_histograms = {}\n",
        "\n",
        "  for name, sample in df.iterrows():\n",
        "    _value = sample.VOI\n",
        "    value = np.array(_value)\n",
        "\n",
        "    # median filter (= median over kernels) and histograms\n",
        "    median_filter = ndimage.median_filter(value, size=kernel_dim, mode='reflect')\n",
        "    median_filter_hist = np.histogram(median_filter, bins=20)\n",
        "    median_filter_second_hist = ndimage.gaussian_laplace(median_filter, sigma=1, mode='reflect')\n",
        "    median_filter_second_hist = np.histogram(median_filter_second_hist, bins=100)\n",
        "\n",
        "    # dispersion filter (= variance over kernels) and histograms\n",
        "    win_mean = ndimage.uniform_filter(value, size=kernel_dim)\n",
        "    win_sqr_mean = ndimage.uniform_filter(value**2, size=kernel_dim)\n",
        "    dispersion = win_sqr_mean - win_mean**2\n",
        "    dispersion_filter_hist = np.histogram(dispersion, bins=20)\n",
        "    dispersion_filter_second_hist = ndimage.gaussian_laplace(dispersion, sigma=1, mode='reflect')\n",
        "    dispersion_filter_second_hist = np.histogram(dispersion_filter_second_hist, bins=100)\n",
        "\n",
        "    # (max - min) filter and histograms\n",
        "    max_filter = ndimage.maximum_filter(value,size=(kernel_dim,kernel_dim,kernel_dim),mode='reflect')\n",
        "    min_filter = ndimage.minimum_filter(value,size=(kernel_dim,kernel_dim,kernel_dim),mode='reflect')\n",
        "    max_min_filter = max_filter - min_filter\n",
        "    max_min_filter_hist = np.histogram(max_min_filter, bins=20)\n",
        "    max_min_filter_second_hist = ndimage.gaussian_laplace(max_min_filter, sigma=1, mode='reflect')\n",
        "    max_min_filter_second_hist = np.histogram(max_min_filter_second_hist, bins=100)\n",
        "\n",
        "    # abs diff filter and histograms\n",
        "    abs_diff_filter = ndimage.generic_filter(value,abs_diff_metric,size=(kernel_dim,kernel_dim,kernel_dim),mode='reflect')\n",
        "    abs_diff_filter_hist = np.histogram(abs_diff_filter, bins=20)\n",
        "    abs_diff_filter_second_hist = ndimage.gaussian_laplace(abs_diff_filter, sigma=1, mode='reflect')\n",
        "    abs_diff_filter_second_hist = np.histogram(abs_diff_filter_second_hist, bins=100)\n",
        "\n",
        "    # mean filter and histograms\n",
        "    mean_filter = ndimage.generic_filter(value,scipy.ndimage.mean,size=(kernel_dim,kernel_dim,kernel_dim),mode='reflect')\n",
        "    mean_filter_hist = np.histogram(mean_filter, bins=20)\n",
        "    mean_filter_second_hist = ndimage.gaussian_laplace(mean_filter, sigma=1, mode='reflect')\n",
        "    mean_filter_second_hist = np.histogram(mean_filter_second_hist, bins=100)\n",
        "        \n",
        "    # autocorrelation filter and histograms\n",
        "    weights = [[[0,0,0], [0,1,0], [0,0,0]],\n",
        "              [[0,1,0], [1,1,1], [0,1,0]],\n",
        "              [[0,0,0], [0,1,0], [0,0,0]]]\n",
        "\n",
        "    autocorrelation = ndimage.correlate(value, weights, mode='reflect')\n",
        "    autocorrelation_filter_hist = np.histogram(autocorrelation, bins=20)\n",
        "    autocorrelation_filter_second_hist = ndimage.gaussian_laplace(autocorrelation, sigma=1, mode='reflect')\n",
        "    autocorrelation_filter_second_hist = np.histogram(autocorrelation_filter_second_hist, bins=100)\n",
        "    \n",
        "    # sobel filter and histograms\n",
        "    sobel_filter = ndimage.sobel(value, axis=-1, mode='reflect')\n",
        "    sobel_filter_hist = np.histogram(sobel_filter, bins=20)\n",
        "    sobel_filter_second_hist = ndimage.gaussian_laplace(sobel_filter, sigma=1, mode='reflect')\n",
        "    sobel_filter_second_hist = np.histogram(sobel_filter_second_hist, bins=100)\n",
        "    \n",
        "    # laplace filter and histograms\n",
        "    laplace_filter = ndimage.laplace(value, mode='reflect')\n",
        "    laplace_filter_hist = np.histogram(laplace_filter, bins=20)\n",
        "    laplace_filter_second_hist = ndimage.gaussian_laplace(laplace_filter, sigma=1, mode='reflect')\n",
        "    laplace_filter_second_hist = np.histogram(laplace_filter_second_hist, bins=100)\n",
        "\n",
        "    # prewitt filter and histograms\n",
        "    prewitt_filter = ndimage.prewitt(value, axis=-1, mode='reflect')\n",
        "    prewitt_filter_hist = np.histogram(prewitt_filter, bins=20)\n",
        "    prewitt_filter_second_hist = ndimage.gaussian_laplace(prewitt_filter, sigma=1, mode='reflect')\n",
        "    prewitt_filter_second_hist = np.histogram(prewitt_filter_second_hist, bins=100)\n",
        "       \n",
        "    #global_entropy\n",
        "    global_entropy = shannon_entropy(value, base=2)\n",
        "\n",
        "    #local_entropy\n",
        "    value_converted=np.array(_value, dtype=np.uint16)\n",
        "    local_entropy = f_entropy(value_converted, ball(5))\n",
        "\n",
        "    # histogram features\n",
        "    hist = np.histogram(value, bins=20)\n",
        "    hist_dist = scipy.stats.rv_histogram(hist)\n",
        "    m, v, s, k = hist_dist.stats(moments='mvsk')\n",
        "    entropy = hist_dist.entropy()\n",
        "    fifth_m = hist_dist.moment(n=5)\n",
        "\n",
        "    # 2-order histogram features\n",
        "    second = ndimage.gaussian_laplace(value, sigma=1, mode='reflect')\n",
        "    second_hist = np.histogram(second, bins=100)\n",
        "    second_hist_dist = scipy.stats.rv_histogram(second_hist)\n",
        "\n",
        "    # mean\n",
        "    avg = [mean(lista) for liste in value for lista in liste]\n",
        "    avg = mean(avg)\n",
        "\n",
        "    # variance\n",
        "    var = value.var()\n",
        "    \n",
        "\n",
        "    stat_quantity = { 'Mean' : avg, \n",
        "                      'Variance' : var,\n",
        "                    }\n",
        "                    \n",
        "    stat_quantities[name] = stat_quantity\n",
        "\n",
        "    stat_feature = {'Median filter': median_filter,\n",
        "                    'Dispersion': dispersion,\n",
        "                    'Max Min': max_min_filter,\n",
        "                    'Abs Diff': abs_diff_filter,\n",
        "                    'Mean': mean_filter,\n",
        "                    'Autocorrelation': autocorrelation,\n",
        "                    'Sobel': sobel_filter,\n",
        "                    'Laplace': laplace_filter,\n",
        "                    'Prewitt': prewitt_filter,\n",
        "                    'Global entropy': global_entropy,\n",
        "                    'Local entropy': local_entropy,\n",
        "                                        'Second Histogram': second_hist,\n",
        "                    }\n",
        "\n",
        "    stat_features[name] = stat_feature\n",
        "\n",
        "    histogram = {'Volumes': hist,\n",
        "                 'Histogram statistics': [m, v, s, k, entropy, fifth_m],\n",
        "                 'Median filter': median_filter_hist,\n",
        "                 'Dispersion': dispersion_filter_hist,\n",
        "                 'Max Min': max_min_filter_hist,\n",
        "                 'Abs Diff': abs_diff_filter_hist,\n",
        "                 'Mean': mean_filter_hist,\n",
        "                 'Autocorrelation': autocorrelation_filter_hist,\n",
        "                 'Sobel': sobel_filter_hist,\n",
        "                 'Laplace': laplace_filter_hist,\n",
        "                 'Prewitt': prewitt_filter_hist,\n",
        "                 }\n",
        "\n",
        "    histograms[name] = histogram           \n",
        "                 \n",
        "    second_histogram = {'Volumes': second_hist,\n",
        "                        'Median filter': median_filter_second_hist,\n",
        "                        'Dispersion': dispersion_filter_second_hist,\n",
        "                        'Max Min': max_min_filter_second_hist,\n",
        "                        'Abs Diff': abs_diff_filter_second_hist,\n",
        "                        'Mean': mean_filter_second_hist,\n",
        "                        'Autocorrelation': autocorrelation_filter_second_hist,\n",
        "                        'Sobel': sobel_filter_second_hist,\n",
        "                        'Laplace': laplace_filter_second_hist,\n",
        "                        'Prewitt': prewitt_filter_second_hist,\n",
        "                        }  \n",
        "\n",
        "    second_histograms[name] = second_histogram                        \n",
        "\n",
        "  stat_quantities = pd.DataFrame.from_dict(stat_quantities, orient = 'index')\n",
        "  stat_features = pd.DataFrame.from_dict(stat_features, orient='index')\n",
        "  histograms = pd.DataFrame.from_dict(histograms, orient='index')\n",
        "  second_histograms = pd.DataFrame.from_dict(second_histograms, orient='index')\n",
        "  \n",
        "  # entropy of filters \n",
        "  no_filters = {'Global entropy', 'Local entropy','Histogram','Histogram statistics', 'Second Histogram' };\n",
        "  entropy_of_filters = {};\n",
        "  for colName, colData in stat_features.iteritems():\n",
        "    if colName not in no_filters: \n",
        "      entropies = [];\n",
        "      for elem in stat_features[colName]:\n",
        "        entropies.append(shannon_entropy(np.array(elem),base = 2))\n",
        "      entropy_of_filters[colName] = entropies\n",
        "\n",
        "  entropy_of_filters = pd.DataFrame.from_dict(entropy_of_filters, orient = 'index')\n",
        "\n",
        "  return stat_features, entropy_of_filters, stat_quantities, histograms, second_histograms\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\tstat_features: dataframe containing, for each patient\\n\\t- Median filter\\n\\t- Dispersion\\n  - Max Min\\n  - Abs Diff\\n  - Mean\\n  - Autocorrelation\\n  - Sobel\\n  - Laplace\\n  - Prewitt\\n  - Global entropy\\n  - Local entropy\\n\\t- Histogram\\n\\t- Histogram statistics\\n\\t- Second Histogram\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jszeZ08Aa-JK"
      },
      "source": [
        "# **1-D entropy functions** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPfJgOCFbIBt"
      },
      "source": [
        "# make_1D_functions(dataset)\n",
        "# Input: volumes from json file\n",
        "# Output: - entropy function along x-axis\n",
        "#         - entropy function along y-axis\n",
        "#         - entropy function along z-axis\n",
        "#         - variance function along x-axis\n",
        "#         - first differences function derived by entropy along x-axis\n",
        "#         - entropy function along x-axis cutted by one pixel on each side\n",
        "#         - entropy function along x-axis cutted by three pixels on each side\n",
        "#         - total variation of the entropy function along x-axis\n",
        "# Each function is obtained by computing a scalar index for each surface of the volume along a particular direction\n",
        "# The output is organized in a dataframe, where the rows are the patients with their identificative code and the columns are the functions computed\n",
        "\n",
        "def make_1D_functions(dataset):\n",
        "  entropy_functions={}\n",
        "  \n",
        "\n",
        "  for name, sample in dataset.iterrows():\n",
        "      _value = sample.VOI\n",
        "      value = np.array(_value)\n",
        "      entropy_x=[]\n",
        "      entropy_y=[]\n",
        "      entropy_z=[]\n",
        "      der_entr_x=[]\n",
        "      entropy_x_cut=[]\n",
        "      var = []\n",
        "      var_tot_x=0\n",
        "      \n",
        "      for i in range(30):\n",
        "          entropy_x.append( shannon_entropy(value[:,:,i], base=2));\n",
        "          var.append(value[:,:,i].var())\n",
        "\n",
        "      for j in range(10):\n",
        "          entropy_y.append( shannon_entropy(value[:,j,:], base=2));\n",
        "      for z in range(10):\n",
        "            entropy_z.append( shannon_entropy(value[z,:,:], base=2));\n",
        "      for i in range(29):\n",
        "          der_entr_x.append(entropy_x[i+1]-entropy_x[i])\n",
        "          var_tot_x=var_tot_x+ abs(entropy_x[i+1]-entropy_x[i])\n",
        "      entropy_x_cut_small=entropy_x[1:29]\n",
        "      entropy_x_cut_large=entropy_x[3:27]\n",
        "\n",
        "      stat_feature = {'entropy_x' : entropy_x,\n",
        "                      'entropy_y' : entropy_y,\n",
        "                      'entropy_z' : entropy_z,\n",
        "                      'variance_x': var,\n",
        "                      'der_entr_x': der_entr_x,\n",
        "                      'entropy_x_cut_small': entropy_x_cut_small,\n",
        "                      'entropy_x_cut_large': entropy_x_cut_large,\n",
        "                      'var_tot_x' : var_tot_x,\n",
        "                      }\n",
        "      entropy_functions[name] = stat_feature\n",
        "      \n",
        "  entropy_functions = pd.DataFrame.from_dict(entropy_functions, orient='index')\n",
        "  return entropy_functions\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}